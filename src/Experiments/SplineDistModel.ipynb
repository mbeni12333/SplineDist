{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "from Models.splinedist import *\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, RichProgressBar, RichModelSummary\n",
    "from Datasets.DSB18 import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\n",
    "    save_dir=os.path.join(os.getcwd(), \"pl_logs\"),\n",
    "    name=\"spline_dist\",\n",
    "    log_graph=True,\n",
    "    default_hp_metric=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"Models/weights\",\n",
    "    filename=\"splineDist-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=5,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "earlystoping_callback = EarlyStopping(\"val_loss\")\n",
    "\n",
    "lr_logger = LearningRateMonitor(logging_interval=\"step\")\n",
    "summary = RichModelSummary(max_depth=-1)\n",
    "progressbar = RichProgressBar()\n",
    "\n",
    "callbacks = [progressbar, checkpoint_callback, lr_logger]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbenimam\\anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = SplineDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(max_epochs=2,\n",
    "#                      gpus=1,\n",
    "#                      callbacks=callbacks,\n",
    "#                      logger=logger)\n",
    "# trainer.fit(model, Nuclie_datamodule())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.onnx.export(model, torch.rand(1, 3, 256, 256), \"src/Models/onnx/splineDist.onnx\",  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Nuclie_datamodule()\n",
    "batch_x, batch_y = next(iter(data.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "(objectProbas, angles, distances, controlPoints) = model(batch_x.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 256, 256]), torch.Size([4, 8, 2, 256, 256]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectProbas.shape, controlPoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 8]),\n",
       " torch.Size([4, 8, 2, 256, 256]),\n",
       " torch.Size([700, 4, 2, 256, 256]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "(targetObjectProbas, targetOverlapProbas, targetContours) = batch_y\n",
    "B3M = getBsplineMatrix(700, 3, 8).float().to(\"cuda\")\n",
    "\n",
    "contours = getContourSamples(controlPoints, B3M)\n",
    "\n",
    "B3M.shape, controlPoints.shape, contours.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 65536, 700, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "contours = contours.permute(1, 0, 2, 3, 4).reshape(4, -1, 700, 2)\n",
    "contours.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetObjectProbas = targetObjectProbas.to(\"cuda\")\n",
    "lossObjectProba = F.binary_cross_entropy(objectProbas, targetObjectProbas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 65536, 700, 2]), torch.Size([4, 65536]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours.shape, objectProbas.reshape(4, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loss 2\n",
    "# non maximum suppression\n",
    "postProcessed = nonMaximumSuppresionBatch(objectProbas.reshape(4, -1).detach().cpu().numpy(),\n",
    "                                          contours.detach().cpu().numpy(),\n",
    "                                          0.5,\n",
    "                                          0.1)\n",
    "# find the associated instances from postProcessed with the ground truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TP, FP, FN = matchInstances(postProcessed, targetContours)\n",
    "torch.stack(tuple(computeDistanceBetweenInstance(postProcessed[id1], targetContours[id2]) \n",
    "                        for id1, id2 in TP)).sum()\n",
    "precision = len(TP) / (len(TP) + len(FP) + 1)\n",
    "recall = len(TP) / (len(TP) + len(FN)+1)\n",
    "# compute the sum of the distances with predicted instances and the ground truth\n",
    "lossDistance = 0\n",
    "# loss 3 sum of the two losses\n",
    "finalLoss = lossObjectProba + self.lambda1*lossDistance\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebff40c868104df1b603b373dc12d00c9e5c3d242027624dfb1be5c162464bd0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
