{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import batched_nms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "sys.path.append(\".\")\n",
    "\n",
    "from Models.splinedist import *\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from Datasets.CISD import *\n",
    "from Datasets.DSB18 import * \n",
    "from torchvision import io\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pl.seed_everything(47)\n",
    "# data = CISD_datamodule(path=\"Datasets/CISD/CISD.json\", root=\"Datasets/CISD/center_slice\", contourSize=500)\n",
    "# batch_x, batch_y = next(iter(data.val_dataloader()))\n",
    "# showBatch((batch_x, batch_y))\n",
    "# !pip install shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "modelName = \"Experiments/Models_final21/weights/splineDist-CISD10-epoch=101-loss_val=5.61.ckpt\"\n",
    "# modelName = \"Experiments/Models_final2/weights/splineDist-CISD4-epoch=86-loss_val=0.08.ckpt\"\n",
    "model = SplineDist.load_from_checkpoint(\n",
    "    checkpoint_path=modelName)\n",
    "device = \"cuda:4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on costum images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transforms = get_transforms(0.5, 0.5)\n",
    "\n",
    "# model = model.to(device)\n",
    "model = model.to(device)\n",
    "MAX_CONTOUR_SIZE = 256\n",
    "threshold = 0.2\n",
    "nms_threshold = 0.4\n",
    "num_samples = 200\n",
    "# MAX_CONTOUR_SIZE = 500\n",
    "for image in glob.glob(\"inferenceCISD/*.jpg\"):\n",
    "    print(image)\n",
    "    img = io.read_image(image, io.ImageReadMode.RGB).float()/255\n",
    "    img = transforms(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        (objectProbas, angles, distances, controlPoints, objectOverlap) = model(img)\n",
    "        objectProbas = torch.sigmoid(objectProbas)\n",
    "        objectOverlap = torch.sigmoid(objectOverlap)\n",
    "        contours = getContourSamples(controlPoints, model.B3M).permute(1, 2, 3, 0, 4)\n",
    "        contours = contours.reshape(-1, MAX_CONTOUR_SIZE, 2)\n",
    "        \n",
    "                \n",
    "        overlap = objectOverlap[0, 0].detach()\n",
    "        overlap = (overlap - overlap.min())/(overlap.max() - overlap.min())\n",
    "        objprob = objectProbas[0, 0].detach()\n",
    "        objprop = objprob * (1 - overlap)\n",
    "        \n",
    "        objprop_t = objprop * (objprop > threshold)\n",
    "        objprop_t = objprop_t / objprop_t.sum()\n",
    "        \n",
    "        \n",
    "        objprop_t = objprop_t.flatten().cpu()\n",
    "        cum_objprop_t = np.cumsum(objprop_t)\n",
    "\n",
    "        coordinates_x = []\n",
    "        coordinates_y = []\n",
    "        # map uniform samples to pixels\n",
    "        for i, z in enumerate(np.random.uniform(size=num_samples)):\n",
    "            diff = cum_objprop_t - z\n",
    "\n",
    "            mask = np.ma.less_equal(diff, 0)\n",
    "            masked_diff = np.ma.masked_array(diff, mask)\n",
    "\n",
    "            # position in 1D-array where x is closest but greater than array value\n",
    "            min_pos = masked_diff.argmin()\n",
    "\n",
    "            # retrieve pixel coordinates\n",
    "            x = min_pos % 256\n",
    "            y = min_pos // 256\n",
    "\n",
    "            coordinates_x.append(x)\n",
    "            coordinates_y.append(y)\n",
    "        \n",
    "\n",
    "        xmin = torch.amin(contours[:, :, 1], dim=-1) \n",
    "        xmax = torch.amax(contours[:, :, 1], dim=-1)\n",
    "        ymin = torch.amin(contours[:, :, 0], dim=-1)\n",
    "        ymax = torch.amax(contours[:, :, 0], dim=-1)\n",
    "\n",
    "        bboxes = torch.stack([xmin, ymin, xmax, ymax], -1)\n",
    "        bboxes0 = torch.stack([xmin, ymin, xmax, ymax], -1)\n",
    "        \n",
    "        scores = objprop.reshape(256*256)\n",
    "\n",
    "        bboxes = bboxes[scores>threshold]\n",
    "        scores2 = scores[scores>threshold]\n",
    "\n",
    "        selectedIds = batched_nms(bboxes, scores2, torch.ones(len(scores2)), iou_threshold=nms_threshold)\n",
    "\n",
    "        bboxes = bboxes.detach().cpu().numpy()\n",
    "        selectedIds = selectedIds.detach().cpu().numpy()\n",
    "\n",
    "        rects = bboxes[selectedIds]\n",
    "        \n",
    "        \n",
    "        scores3 = objprob.reshape(256*256)\n",
    "\n",
    "        bboxes = bboxes0[scores3>threshold]\n",
    "        scores4 = scores[scores3>threshold]\n",
    "\n",
    "        selectedIds2 = batched_nms(bboxes, scores4, torch.ones(len(scores4)), iou_threshold=nms_threshold)\n",
    "\n",
    "        bboxes = bboxes.detach().cpu().numpy()\n",
    "        selectedIds2 = selectedIds2.detach().cpu().numpy()\n",
    "\n",
    "        rects2 = bboxes[selectedIds2]\n",
    "        \n",
    "        \n",
    "\n",
    "        # polygon IOU\n",
    "\n",
    "#         scores = objectProbas[0].flatten(1).cpu().detach().numpy()\n",
    "#         sortedInstances = np.argsort(scores, axis=1).copy()\n",
    "\n",
    "#         til = [np.searchsorted(scores[0, sortedInstances[0]], threshold)]\n",
    "\n",
    "#         contours2 = [contours[til[0]:]]\n",
    "# #         print(til)\n",
    "#         print(len(contours2[0]))\n",
    "#         postProcessed = nonMaximumSuppresion(scores[0, sortedInstances[0, til[0]:]],\n",
    "#                                             contours2[0],\n",
    "#                                             threshold,\n",
    "#                                             nms_threshold)\n",
    "\n",
    "#         contoursSelected, selectedIds = postProcessed\n",
    "#         selectedIds = np.array(selectedIds)\n",
    "        \n",
    "        \n",
    "        # end of the non maximum suppression\n",
    "        \n",
    "        \n",
    "        \n",
    "        image = np.ones((256,256,3), np.uint8)*255\n",
    "        image2 = np.uint8(denormalize(img[0].detach().cpu()).numpy().transpose(1, 2, 0)*255)\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "   \n",
    "    \n",
    "    #     image2 = clahe.apply(image2)\n",
    "        img_yuv = cv2.cvtColor(image2, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "        # equalize the histogram of the Y channel\n",
    "        img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
    "\n",
    "        # convert the YUV image back to RGB format\n",
    "        image2 = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "        \n",
    "    #     image2 = cv2.equalizeHist(image2)\n",
    "        ctrs = contours[scores>threshold][selectedIds].detach().cpu().numpy()\n",
    "        ctrs2 = contours[scores3>threshold][selectedIds2].detach().cpu().numpy()\n",
    "\n",
    "        fig, (ax2, ax3, ax4, ax5, ax6) = plt.subplots(\n",
    "                    1, 5, figsize=(21, 13))\n",
    "        \n",
    "\n",
    "        \n",
    "        ax4.set_title(\"Object Overlap Probaiblities\")\n",
    "        ax4.imshow(overlap.cpu(), cmap='gnuplot2')\n",
    "        \n",
    "        ax5.set_title(\"Object proposal \")\n",
    "        ax5.imshow(objprop.cpu(), cmap='gnuplot2')\n",
    "        \n",
    "\n",
    "        \n",
    "        ax2.set_title(\"Object Probabilities\")\n",
    "        # print(objectProbas.min(), objectProbas.max(), objectProbas.ptp())\n",
    "        ax2.imshow(objprob.cpu(), cmap='gnuplot2')\n",
    "        # plt.subplot(1,4,4)\n",
    "        ax3.set_title(\"Object Instances\")\n",
    "        # instances, colors = getInstancesImageFromContours(objectContours)\n",
    "        #ax4.imshow(denormalize(img[0]).cpu().numpy().transpose(1, 2, 0))\n",
    "        ax3.imshow(image2)\n",
    "        ax3.scatter(coordinates_x, coordinates_y, c=np.random.rand(len(coordinates_x),3), s=10)\n",
    "        # ax4.imshow(instances, alpha=0.3)\n",
    "        colors = [ list(map(lambda x: x/255, getRandomColor())) for j in range(len(contours))]\n",
    "\n",
    "        for j, ct in enumerate(ctrs):\n",
    "            ax3.fill(ctrs[j][:, 0], ctrs[j][:, 1], color=colors[j], alpha=0.1)\n",
    "            ax3.plot(ctrs[j][:, 0], ctrs[j][:, 1], color=colors[j], linewidth=2, linestyle='dashed')\n",
    "            \n",
    "            \n",
    "        ax6.imshow(image2)\n",
    "        # ax4.imshow(instances, alpha=0.3)\n",
    "#         colors = [ list(map(lambda x: x/255, getRandomColor())) for j in range(len(contours))]\n",
    "        ax6.scatter(coordinates_x, coordinates_y, c=np.random.rand(len(coordinates_x),3), s=10)\n",
    "        for j, ct in enumerate(ctrs):\n",
    "            ax6.fill(ctrs2[j][:, 0], ctrs2[j][:, 1], color=colors[j], alpha=0.1)\n",
    "            ax6.plot(ctrs2[j][:, 0], ctrs2[j][:, 1], color=colors[j], linewidth=2, linestyle='dashed')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
